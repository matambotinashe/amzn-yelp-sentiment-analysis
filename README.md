# Embedding Model using sub-words
- In this branch we explore just using sub words in our model that uses an embedding layer.
- We will still play around with the following hyperparameters 
  - embedding dimensions 
  - maximum length of sequence
  - vocabulary size
  - replacing the Flattern layer with the GlobalAveragePooling layer
 
